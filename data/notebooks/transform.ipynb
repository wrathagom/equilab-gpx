{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd31f9d-8035-47ba-9385-2c7dcd06ff3b",
   "metadata": {},
   "source": [
    "# Transform\n",
    "\n",
    "In this notebook we're going to Transform GPX files stored in Digital Ocean spaces.  If you notice, this project is missing an extract step. That's because I have a process setup to upload Equilab data using a Shotrcut on my phone, which is essentially my extract process. Equilab doens't have an API, so I can't extract the data in the traditional sense.\n",
    "\n",
    "Before we get to the fun stuff first we must import:\n",
    "\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d735432-4309-4951-82f0-6717aa167671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bucketstore\n",
    "from geopy import distance as geodistance\n",
    "import geopy\n",
    "import yaml\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d06f4-cfbc-46f2-9f64-bb63aea9825f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "With importing out of the way we'll get a few basics out of the way. The below cell:\n",
    " 1) Loads a file containing connection info to my DO Space\n",
    " 2) Uses the connection info to connect to the space\n",
    " 3) Loads the bucket that all of the data is stored in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af9a2801-726f-46ba-8c68-b4417b733108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"secrets.yml\", 'r') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "bucketstore.login(\n",
    "    access_key_id=cfg['spaces']['access'],\n",
    "    secret_access_key=cfg['spaces']['secret'],\n",
    "    region='nyc3',\n",
    "    endpoint_url=cfg['spaces']['url']\n",
    ")\n",
    "bucket = bucketstore.get('wrathalake')\n",
    "\n",
    "ridesKey = 'intermediate/rides.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3402a78f-bbf3-4a9f-85cf-037545c6817b",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "To keep the code clean we're going to encapsulate a few things in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4874091a-2214-4c2b-88f3-6aa7bf192a40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def processFile(key):\n",
    "    gpx = gpxpy.parse(bucket[key])\n",
    "    \n",
    "    # Choosing to store coordinates in a dict to remove ambiguity. Apparently we can't all agree to use long, lat or lat, long\n",
    "    data = [{\n",
    "        'time': point.time,\n",
    "        'coords': {\n",
    "            'long': point.longitude,\n",
    "            'lat': point.latitude\n",
    "        },\n",
    "        'elevation': point.elevation * 3.28084\n",
    "    } for point in gpx.tracks[0].segments[0].points]\n",
    "    \n",
    "    # Calculating some ride metrics\n",
    "    totalDistance = 0\n",
    "    totalTime = (data[-1]['time'] - data[0]['time']).total_seconds()\n",
    "    totalClimb = 0\n",
    "    \n",
    "    prv = nxt = None\n",
    "    l = len(data)\n",
    "    \n",
    "    for index, obj in enumerate(data):\n",
    "        if index > 0:\n",
    "            prv = data[index - 1]\n",
    "\n",
    "        if index < (l - 1):\n",
    "            nxt = data[index + 1]\n",
    "\n",
    "        if prv is not None:\n",
    "            timeDelta = (obj['time'] - prv['time']).total_seconds()\n",
    "            \n",
    "            # geopy uses coordinates in the (lat, long) format, so we'll create that below.\n",
    "            distance = geodistance.geodesic((obj['coords']['lat'], obj['coords']['long']), (prv['coords']['lat'], prv['coords']['long'])).ft\n",
    "            totalDistance += distance\n",
    "            \n",
    "            speed = (distance / timeDelta) * 0.681818182\n",
    "            \n",
    "            if obj['elevation'] > prv['elevation']:\n",
    "                climb = obj['elevation'] - prv['elevation']\n",
    "                totalClimb += climb\n",
    "            else:\n",
    "                climb = None\n",
    "\n",
    "            obj['timeDelta'] = timeDelta\n",
    "            obj['distance'] = distance\n",
    "            obj['speed'] = speed\n",
    "            obj['climb'] = climb\n",
    "            obj['drop'] = (prv['elevation'] - obj['elevation']) if obj['elevation'] < prv['elevation'] else None\n",
    "        \n",
    "    rideData = {\n",
    "        'rawFile': key,\n",
    "        'interFile': key.replace('raw', 'intermediate').replace('gpx', 'json'),\n",
    "        'rideDate': data[0]['time'].strftime(\"%Y%m%d\"),\n",
    "        'totalTime': totalTime,\n",
    "        'totalDistance': totalDistance,\n",
    "        'totalClimb': totalClimb,\n",
    "        'averageSpeed': (totalDistance / totalTime) * 0.681818182,\n",
    "        'inElastic': False\n",
    "    }\n",
    "    \n",
    "    # Once we're done processing we need to set the time to be something that can be stored in JSON\n",
    "    for index, obj in enumerate(data):\n",
    "        timestamp = obj['time'].isoformat()\n",
    "        obj['time'] = timestamp\n",
    "            \n",
    "    return data, rideData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3da1b6-73fd-466b-beb5-c0ec6aa45fee",
   "metadata": {},
   "source": [
    "## History\n",
    "\n",
    "When ever this process runs it uses a Rides file that documents each ride. If a ride is listed in this file it means that it has already been processed and thus doesn't need processed again.\n",
    "\n",
    "So first things first, let's load the rides file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f99d812-b85c-4c55-9b7c-52e88947163f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 rides that have been processed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rides = json.loads(bucket['intermediate/rides.json'])\n",
    "except:\n",
    "    bucket[ridesKey] = json.dumps({})\n",
    "    rides = {}\n",
    "\n",
    "rideKeys = rides.keys()\n",
    "\n",
    "print('There are {} rides that have been processed.'.format(len(rides.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5bb8e-e414-4555-a9cb-848ca2dbd738",
   "metadata": {},
   "source": [
    "## Raw Ride Files\n",
    "\n",
    "Now that we have a list of files that have been processed we can check all of the files against it and process just the ones that need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42502f04-d4d0-4f99-a381-1f30a5ea0d14",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "objects = bucket.list(prefix='raw/sources/equilab/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a4f28c12-8ae6-42f6-aeb6-6307dc62a489",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing raw/sources/equilab/training-2023-09-09.gpx\n",
      "Processing raw/sources/equilab/training-2023-09-10.gpx\n",
      "Processing raw/sources/equilab/training-2023-09-23.gpx\n",
      "Processing raw/sources/equilab/training-2023-10-14.gpx\n",
      "Processing raw/sources/equilab/training-2023-10-22.gpx\n"
     ]
    }
   ],
   "source": [
    "for obj in objects:\n",
    "    if obj.endswith('.gpx') and obj not in rideKeys:\n",
    "        print('Processing {}'.format(obj))\n",
    "        fileData, rideData = processFile(obj)\n",
    "        \n",
    "        newKey = obj.replace('raw', 'intermediate').replace('gpx', 'json')\n",
    "        bucket[newKey] = json.dumps(fileData)\n",
    "        \n",
    "        rides[obj] = rideData\n",
    "\n",
    "bucket[ridesKey] = json.dumps(rides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1dd8a-9fdc-43b2-990c-fd1c8bfb25c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper Functions\n",
    "\n",
    "The below lines of code are meant as helper functions and in general they should be left commented out. But it's not always a bad thing to leave them uncommented and save them as history for the scheduled process that runs the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68fc7d13-70a5-46eb-8cdd-abc109fbf475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View the rides JSON file\n",
    "# bucket[ridesKey]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8146a328-a3f0-4397-8100-dfbb89ed59ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the rides file, which essentially will restart processing\n",
    "# del bucket[ridesKey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97bcf0f4-b791-461c-9d1c-7468221083c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List all of the ride data in the intermediate directory\n",
    "# bucket.list(prefix='intermediate/sources/equilab/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69902d61-bd45-4f82-905c-9398436d7076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete all of the processes rides\n",
    "# for key in bucket.list(prefix='intermediate/sources/equilab/'):\n",
    "#     del bucket[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "810eea82-6abf-4bdf-b441-202ffcc50bca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'time': '2023-10-22T19:14:40.014000+00:00',\n",
       "  'coords': {'long': -86.0489782, 'lat': 37.9405569},\n",
       "  'elevation': 659.120756},\n",
       " {'time': '2023-10-22T19:14:41+00:00',\n",
       "  'coords': {'long': -86.0489829, 'lat': 37.9405528},\n",
       "  'elevation': 659.776924,\n",
       "  'timeDelta': 0.986,\n",
       "  'distance': 2.0165503741423745,\n",
       "  'speed': 1.3944429107598109,\n",
       "  'climb': 0.6561679999999797,\n",
       "  'drop': None},\n",
       " {'time': '2023-10-22T19:14:42+00:00',\n",
       "  'coords': {'long': -86.0489954, 'lat': 37.9405522},\n",
       "  'elevation': 664.042016,\n",
       "  'timeDelta': 1.0,\n",
       "  'distance': 3.6115741930671343,\n",
       "  'speed': 2.4624369504751504,\n",
       "  'climb': 4.2650919999999815,\n",
       "  'drop': None}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View a few lines from the last fileData processed\n",
    "fileData[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "988eedae-47fb-414f-a7e3-5129c0a41aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw/sources/equilab/training-2023-09-09.gpx': {'rawFile': 'raw/sources/equilab/training-2023-09-09.gpx',\n",
       "  'interFile': 'intermediate/sources/equilab/training-2023-09-09.json',\n",
       "  'rideDate': '20230909',\n",
       "  'totalTime': 6526.014,\n",
       "  'totalDistance': 26598.70310297059,\n",
       "  'totalClimb': 8746.719439999997,\n",
       "  'averageSpeed': 2.778951959530759,\n",
       "  'inElastic': False},\n",
       " 'raw/sources/equilab/training-2023-09-10.gpx': {'rawFile': 'raw/sources/equilab/training-2023-09-10.gpx',\n",
       "  'interFile': 'intermediate/sources/equilab/training-2023-09-10.json',\n",
       "  'rideDate': '20230910',\n",
       "  'totalTime': 7021.024,\n",
       "  'totalDistance': 26223.356190037925,\n",
       "  'totalClimb': 5603.346635999986,\n",
       "  'averageSpeed': 2.5465745514372413,\n",
       "  'inElastic': False},\n",
       " 'raw/sources/equilab/training-2023-09-23.gpx': {'rawFile': 'raw/sources/equilab/training-2023-09-23.gpx',\n",
       "  'interFile': 'intermediate/sources/equilab/training-2023-09-23.json',\n",
       "  'rideDate': '20230923',\n",
       "  'totalTime': 11583.061,\n",
       "  'totalDistance': 39063.74337117145,\n",
       "  'totalClimb': 10789.042340000009,\n",
       "  'averageSpeed': 2.2994241753062226,\n",
       "  'inElastic': False},\n",
       " 'raw/sources/equilab/training-2023-10-14.gpx': {'rawFile': 'raw/sources/equilab/training-2023-10-14.gpx',\n",
       "  'interFile': 'intermediate/sources/equilab/training-2023-10-14.json',\n",
       "  'rideDate': '20231014',\n",
       "  'totalTime': 14425.214,\n",
       "  'totalDistance': 44880.363866589105,\n",
       "  'totalClimb': 16974.738076000252,\n",
       "  'averageSpeed': 2.1213028866688752,\n",
       "  'inElastic': False},\n",
       " 'raw/sources/equilab/training-2023-10-22.gpx': {'rawFile': 'raw/sources/equilab/training-2023-10-22.gpx',\n",
       "  'interFile': 'intermediate/sources/equilab/training-2023-10-22.json',\n",
       "  'rideDate': '20231022',\n",
       "  'totalTime': 10736.132,\n",
       "  'totalDistance': 42759.16011604784,\n",
       "  'totalClimb': 15157.808884000093,\n",
       "  'averageSpeed': 2.7155005931531626,\n",
       "  'inElastic': False}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the rides data JSON\n",
    "rides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681602b7-275a-4b95-8346-13b8ca5d49e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
